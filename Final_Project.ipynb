{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from skimage.io import imread\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_folder = Path('.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Reading images and creating labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_image_and_create_label_from_filepath(filepath):\n",
    "    img = imread(filepath)\n",
    "    label = filepath.parts[0]\n",
    "    return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = zip(*[read_image_and_create_label_from_filepath(filepath) for filepath in main_folder.rglob(\"*.png\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = shuffle(images, labels)\n",
    "images = np.asarray(images)\n",
    "labels = np.asarray(labels)\n",
    "print('Dataset and image sizes: {}'.format(images.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Changing created labels into numbers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "labels = le.fit_transform(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Data Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(images[0].max())\n",
    "print(images[0].min())\n",
    "images = images / 255\n",
    "print(images[0].max())\n",
    "print(images[0].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(labels)\n",
    "print(np.unique(labels, return_counts=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Creating training, valid, test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_x, x_test, training_y, y_test = train_test_split(images, labels, test_size = 0.1, random_state = 42) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of elements in training_x: {}'.format(len(training_x)))\n",
    "print('Number of elements in training_y: {}'.format(len(training_y)))\n",
    "print('Number of elements in x_test: {}'.format(len(x_test)))\n",
    "print('Number of elements in y_test: {}'.format(len(y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split training sets into smaller training and validation sets - test dataset will be used at the very end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_valid, y_train, y_valid = train_test_split(training_x, training_y, test_size = 0.2, random_state = 42) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of elements in x_train: {}'.format(len(x_train)))\n",
    "print('Number of elements in y_train: {}'.format(len(y_train)))\n",
    "print('Number of elements in x_valid: {}'.format(len(x_valid)))\n",
    "print('Number of elements in y_valid: {}'.format(len(y_valid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_names = list(np.unique(y_valid))\n",
    "labels_dict = dict(zip(labels_names, ['pap', 'rock', 'sciss']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_imgs(x_set, y_set, names):\n",
    "    fig, ax = plt.subplots(4, 4, figsize=(9, 9), sharex='col', sharey='row')\n",
    "    for x in range(4):\n",
    "        for y in range(4):\n",
    "            idx = random.randint(0, len(x_set)-1)\n",
    "            ax[x,y].imshow(x_set[idx], cmap='gray')\n",
    "            ax[x,y].set_title(names[int(y_set[idx])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_imgs(x_train, y_train, labels_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Create a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D\n",
    "from sklearn.utils import class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(Conv2D(9, (5, 5), activation='relu', input_shape=(200, 300, 3), name='L1'))\n",
    "model.add(MaxPooling2D((2, 2), name='P1'))\n",
    "model.add(Conv2D(9, (5, 5), activation='relu', name='L2'))\n",
    "model.add(MaxPooling2D((2, 2), name='P2'))\n",
    "model.add(Conv2D(9, (5, 5), activation='relu', name='L3'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=opt,\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x_train, y_train, epochs=10, batch_size=32, validation_data=(x_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'], label='loss')\n",
    "plt.plot(history.history['val_loss'], label = 'val_loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.legend(loc='upper right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'], label = 'accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='lower right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(x_valid, y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysis of hyperparameters:\n",
    "- 10 epoch, batch_size=16, learning_rate=0.1 - [1.097268682042556, 0.37055838]\n",
    " \n",
    "- 10 epoch, batch_size=32, learning_rate=0.1 - [1.1198053821896135, 0.3401015]\n",
    "\n",
    "- 10 epoch, batch_size=64, learning_rate=0.1 - [1.094128987712505, 0.37055838]\n",
    "\n",
    "- 10 epoch, batch_size=64, learning_rate=0.001 - [0.1878916552375416, 0.9407783]\n",
    "\n",
    "- 10 epoch, batch_size=64, learning_rate=0.01 - [1.0990896372222254, 0.2893401]\n",
    "\n",
    "- 10 epoch, batch_size=64, learning_rate=1.0 - [1.0991522888645102, 0.3401015]\n",
    "\n",
    "- 10 epoch, batch_size=32, learning_rate=0.001 - [0.17450435519141227, 0.964467]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict_classes(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(predictions)\n",
    "print(np.unique(predictions, return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_imgs_with_predictions(x_set, y_set, preds, names):\n",
    "    fig, ax = plt.subplots(4, 4, figsize=(8, 8), sharex='col', sharey='row')\n",
    "    for x in range(4):\n",
    "        for y in range(4):\n",
    "            idx = random.randint(0, x_set.shape[0]-1)\n",
    "            ax[x,y].imshow(x_set[idx], cmap='gray')\n",
    "            ax[x,y].set_title('y:{}, pr:{}'.format(names[int(y_set[idx])], names[int(preds[idx])]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong_indexes = [i for i, prediction in enumerate(predictions) if prediction != y_test[i]]\n",
    "print('Number of wrong predictions: {}'.format(len(wrong_indexes)))\n",
    "print('Number of samples in x_test: {}'.format(len(x_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_imgs_with_predictions(x_test, y_test, predictions, labels_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wrong predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_imgs_with_predictions(x_test[wrong_indexes], y_test[wrong_indexes], predictions[wrong_indexes], labels_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mgrz",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
